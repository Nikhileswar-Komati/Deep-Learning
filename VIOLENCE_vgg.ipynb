{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VIOLENCE_95",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPnXGZCVC/EQg4jP7GyrLdO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nikhileswar-Komati/Deep-Learning/blob/master/VIOLENCE_vgg.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCNyDUcshXMF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.environ['KAGGLE_USERNAME'] = \"nikhileswarkomati\"\n",
        "os.environ['KAGGLE_KEY'] =\"e75f0f971ce7ce2b2bc748fa02cbafd1\"\n",
        "!kaggle datasets download -d mohamedmustafa/real-life-violence-situations-dataset -p /content"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhyTeEvRi03B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip \\*.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KAZc_kK2FHc5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install keras-video-generators"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PxMGwf7FaDe8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras_video import VideoFrameGenerator\n",
        "# use sub directories names as classes\n",
        "classes = ['Violence', 'NonViolence']\n",
        "classes.sort()\n",
        "# some global params\n",
        "SIZE = (150,150)\n",
        "CHANNELS = 3\n",
        "NBFRAME = 6\n",
        "BS = 8\n",
        "# pattern to get videos and classes\n",
        "glob_pattern = '/content/Real Life Violence Dataset/{classname}/*'\n",
        "# for data augmentation\n",
        "data_aug = keras.preprocessing.image.ImageDataGenerator(\n",
        "    zoom_range=.1,\n",
        "    rotation_range=8,\n",
        "    width_shift_range=.1,\n",
        "    height_shift_range=.1)\n",
        "# Create video frame generator\n",
        "train = VideoFrameGenerator(\n",
        "    classes=classes, \n",
        "    glob_pattern=glob_pattern,\n",
        "    nb_frames=NBFRAME,\n",
        "    split_val=.10, \n",
        "    shuffle=True,\n",
        "    batch_size=BS,\n",
        "    target_shape=SIZE,\n",
        "    nb_channel=CHANNELS,\n",
        "    transformation=data_aug,\n",
        "    use_frame_cache=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SdKvRauSep53",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "valid = train.get_validation_generator()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AaZHWFRG4azb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras_video.utils\n",
        "keras_video.utils.show_sample(train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGemFGNt23ZH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import Conv2D, BatchNormalization, MaxPool2D, GlobalMaxPool2D\n",
        "from keras.layers import TimeDistributed, GRU, Dense, Dropout\n",
        "import keras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihoNNO54e3sE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_vgg(shape=(150, 150, 3), nbout=2):\n",
        "    model = keras.applications.VGG19(\n",
        "        include_top=False,\n",
        "        input_shape=shape,\n",
        "        weights='imagenet')\n",
        "    # Keep 9 layers to train﻿﻿\n",
        "    trainable = 9\n",
        "    for layer in model.layers[:-trainable]:\n",
        "        layer.trainable = False\n",
        "    for layer in model.layers[-trainable:]:\n",
        "        layer.trainable = True\n",
        "    output = GlobalMaxPool2D()\n",
        "    return keras.Sequential([model, output])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VKzjWRJj2n4J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def action_model(shape=(6, 150, 150, 3), nbout=2):\n",
        "    convnet = build_vgg(shape[1:], nbout = 2)\n",
        "    \n",
        "    # then create our final model\n",
        "    model = keras.Sequential()\n",
        "    model.add(TimeDistributed(convnet, input_shape = shape))\n",
        "    # here, you can also use GRU or LSTM\n",
        "    model.add(GRU(64))\n",
        "    # and finally, we make a decision network\n",
        "    model.add(Dense(1024, activation='relu'))\n",
        "    model.add(Dropout(.5))\n",
        "    model.add(Dense(512, activation='relu'))\n",
        "    model.add(Dropout(.5))\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dropout(.5))\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(Dense(nbout, activation='softmax'))\n",
        "    return model\n",
        "    # ..."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5r8nJQ9Wk1Hb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "INSHAPE=(NBFRAME,) + SIZE + (CHANNELS,) # (5, 224, 224, 2)\n",
        "model = action_model(INSHAPE, len(classes))\n",
        "optimizer = keras.optimizers.SGD()\n",
        "model.compile(\n",
        "    optimizer,\n",
        "    'categorical_crossentropy',\n",
        "    metrics=['acc']\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LijrxXiXlF7d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir chkp\n",
        "EPOCHS=20\n",
        "# create a \"chkp\" directory before to run that\n",
        "# because ModelCheckpoint will write models inside\n",
        "callbacks = [\n",
        "    keras.callbacks.ReduceLROnPlateau(verbose=1),\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        'chkp/weights.{epoch:02d}-{val_loss:.2f}.hdf5',\n",
        "        verbose=1),\n",
        "]\n",
        "history = model.fit_generator(\n",
        "    train,\n",
        "    validation_data=valid,\n",
        "    verbose=1,\n",
        "    epochs=EPOCHS,\n",
        "    callbacks=callbacks\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wFeOnrWlaRx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "acc=history.history['acc']\n",
        "val_acc=history.history['val_acc']\n",
        "loss=history.history['loss']\n",
        "val_loss=history.history['val_loss']\n",
        "\n",
        "epochs=range(len(acc)) # Get number of epochs\n",
        "\n",
        "#------------------------------------------------\n",
        "# Plot training and validation accuracy per epoch\n",
        "#------------------------------------------------\n",
        "plt.plot(epochs, acc, 'r', label = \"Training Accuracy\")\n",
        "plt.plot(epochs, val_acc, 'b', label = \"Validation Accuracy\")\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "\n",
        "#------------------------------------------------\n",
        "# Plot training and validation loss per epoch\n",
        "#------------------------------------------------\n",
        "plt.plot(epochs, loss, 'r', label = \"Training Loss\")\n",
        "plt.plot(epochs, val_loss, 'b', label = \"Validation Loss\")\n",
        "\n",
        "\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aR3SqHGtu30g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9syxzS7xcK06",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}